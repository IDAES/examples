{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "header",
          "hide-cell"
        ]
      },
      "outputs": [],
      "source": [
        "###############################################################################\n",
        "# The Institute for the Design of Advanced Energy Systems Integrated Platform\n",
        "# Framework (IDAES IP) was produced under the DOE Institute for the\n",
        "# Design of Advanced Energy Systems (IDAES).\n",
        "#\n",
        "# Copyright (c) 2018-2025 by the software owners: The Regents of the\n",
        "# University of California, through Lawrence Berkeley National Laboratory,\n",
        "# National Technology & Engineering Solutions of Sandia, LLC, Carnegie Mellon\n",
        "# University, West Virginia University Research Corporation, et al.\n",
        "# All rights reserved.  Please see the files COPYRIGHT.md and LICENSE.md\n",
        "# for full copyright and license information.\n",
        "#\n",
        "###############################################################################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "###############################################################################\n",
        "# The Institute for the Design of Advanced Energy Systems Integrated Platform\n",
        "# Framework (IDAES IP) was produced under the DOE Institute for the\n",
        "# Design of Advanced Energy Systems (IDAES).\n",
        "#\n",
        "# Copyright (c) 2018-2023 by the software owners: The Regents of the\n",
        "# University of California, through Lawrence Berkeley National Laboratory,\n",
        "# National Technology & Engineering Solutions of Sandia, LLC, Carnegie Mellon\n",
        "# University, West Virginia University Research Corporation, et al.\n",
        "# All rights reserved.  Please see the files COPYRIGHT.md and LICENSE.md\n",
        "# for full copyright and license information.\n",
        "###############################################################################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Supercritical CO2 Property Surrogate with OMLT Surrogate Object - Training Surrogate (Part 1)\n",
        "\n",
        "Maintainer: Javal Vyas\n",
        "\n",
        "Author: Javal Vyas\n",
        "\n",
        "Updated: 2024-01-24\n",
        "\n",
        "## 1. Introduction\n",
        "This notebook illustrates the use of KerasSurrogate API leveraging TensorFlow Keras and OMLT package to produce an ML surrogate based on supercritical CO2 data from simulation using REFPROP package.\n",
        "\n",
        "There are several reasons to build surrogate models for complex processes, even when higher fidelity models already exist (e.g., reduce model size, improve convergence reliability, replace models with externally compiled code and make them fully-equation oriented).\n",
        "\n",
        "In this example, we intend to make a surrogate for the physical properties of S-CO2 to be embedded in the property package. This property package will be used to get the physical properties of S-CO2 in the flowsheet simulation. To learn more about property package, see the [IDAES-PSE](https://github.com/IDAES/idaes-pse) Github Page or IDAES [Read-the-docs](https://idaes-pse.readthedocs.io/en/latest/). \n",
        "\n",
        "### 1.1 Need for ML Surrogates\n",
        "\n",
        "The properties predicted by the surrogate are enthalpy and entropy of the S-CO2 based on the \n",
        "pressure and temperature of the system. The analytical equation of getting the enthalpy and entropy from pressure and temperature are in the differential form and would make the problem a DAE system. To counter this problem and keep the problem algebraic, we will use the ML surrogates and relate enthalpy and entropy with the pressure and temperature as an algebraic equation.\n",
        "\n",
        "### 1.2 Supercritical CO2 cycle process\n",
        "\n",
        "The following flowsheet will be used to optimize the design for the cooling of the fusion reactor using supercritical CO2 cycle. We shall focus on training the surrogate for this notebook and move to constructing the flowsheet and the properties package in the subsequent notebooks. The take away from this flowsheet is that, 3 variables can be measured in any given unit which are flow, pressure and temperature and other properties can be calculated using them. Thus, surrogate should have pressure and temperature as the inputs.\n",
        "\n",
        "In this example, we will train a tanh model from our data and then demonstrate that we can solve an optimization problem with that surrogate model. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "from IPython.display import Image\n",
        "from pathlib import Path\n",
        "\n",
        "\n",
        "def datafile_path(name):\n",
        "    return Path(\"..\") / name\n",
        "\n",
        "\n",
        "Image(datafile_path(\"CO2_flowsheet.png\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Training and Validating Surrogate\n",
        "\n",
        "First, let's import the required Python and IDAES modules:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import statements\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random as rn\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "\n",
        "# Import IDAES libraries\n",
        "from idaes.core.surrogate.sampling.data_utils import split_training_validation\n",
        "from idaes.core.surrogate.sampling.scaling import OffsetScaler\n",
        "from idaes.core.surrogate.keras_surrogate import KerasSurrogate\n",
        "from idaes.core.surrogate.plotting.sm_plotter import (\n",
        "    surrogate_scatter2D,\n",
        "    surrogate_parity,\n",
        "    surrogate_residual,\n",
        ")\n",
        "\n",
        "# fix environment variables to ensure consist neural network training\n",
        "os.environ[\"PYTHONHASHSEED\"] = \"0\"\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
        "np.random.seed(46)\n",
        "rn.seed(1342)\n",
        "tf.random.set_seed(62)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.1 Importing Training and Validation Datasets\n",
        "\n",
        "In this section, we read the dataset from the CSV file located in this directory. 500 data points were simulated for S-CO2 physical properties using REFPROP package. This example is trained on the entire dataset because neural  network can overfit on smaller dataset. The data is separated using an 80/20 split into training and validation data using the IDAES split_training_validation() method.\n",
        "\n",
        "We rename the column headers because they contained \".\", which may cause errors while reading the column names in subsequent code, thus as a good practice we change them to the variable names to be used in the property package. Further, the input variables are **pressure**, **temperature** , while the output variables are **enth_mol**, **entr_mol**, hence we create two new dataframes for the input and output variables. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import training data\n",
        "np.set_printoptions(precision=6, suppress=True)\n",
        "\n",
        "csv_data = pd.read_csv(datafile_path(\"500_Points_DataSet.csv\"))\n",
        "csv_data.columns.values[0:6] = [\n",
        "    \"pressure\",\n",
        "    \"temperature\",\n",
        "    \"enth_mol\",\n",
        "    \"entr_mol\",\n",
        "    \"CO2_enthalpy\",\n",
        "    \"CO2_entropy\",\n",
        "]\n",
        "data = csv_data.sample(n=500)\n",
        "\n",
        "# Creating input_data and output_data from data\n",
        "input_data = data.iloc[:, :2]\n",
        "output_data = data.iloc[:, 2:4]\n",
        "\n",
        "# Define labels, and split training and validation data\n",
        "input_labels = input_data.columns\n",
        "output_labels = output_data.columns\n",
        "\n",
        "n_data = data[input_labels[0]].size\n",
        "data_training, data_validation = split_training_validation(data, 0.8, seed=n_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.2 Training Surrogate with TensorFlow Keras\n",
        "TensorFlow Keras provides an interface to pass regression settings, build neural networks and train surrogate models. Keras enables the usage of two API formats: Sequential and Functional. While the Functional API offers more versatility, including multiple input and output layers in a single neural network, the Sequential API is more stable and user-friendly. Further, the Sequential API integrates cleanly with existing IDAES surrogate tools and will be utilized in this example.\n",
        "\n",
        "In the code below, we build the neural network structure based on our training data structure and desired regression settings. Offline, neural network models were trained for the list of settings below, and the options bolded and italicized were determined to have the minimum mean squared error for the dataset:\n",
        "\n",
        "* Activation function: sigmoid, **tanh**\n",
        "* Optimizer: **Adam**\n",
        "* Number of hidden layers: 3, **4**, 5, 6\n",
        "* Number of neurons per layer: **20**, 40, 60\n",
        "\n",
        "Important thing to note here is that we do not use ReLU activation function for the training as the flowsheet we intend to solve with this surrogate model is a NLP problem and using ReLU activation function will make it an MINLP. Another thing to note here is the network is smaller (4,20) in order to avoid overfitting.  \n",
        "\n",
        "Typically, Sequential Keras models are built vertically; the dataset is scaled and normalized. The network is defined for the input layer, hidden layers, and output layer for the passed activation functions and network/layer sizes. Then, the model is compiled using the passed optimizer and trained using a desired number of epochs. Keras internally validates while training and updates each epoch's model weight (coefficient) values.\n",
        "\n",
        "Finally, after training the model, we save the results and model expressions to a folder that contains a serialized JSON file. Serializing the model in this fashion enables importing a previously trained set of surrogate models into external flowsheets. This feature will be used later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# selected settings for regression (best fit from options above)\n",
        "activation, optimizer, n_hidden_layers, n_nodes_per_layer = \"tanh\", \"Adam\", 4, 20\n",
        "loss, metrics = \"mse\", [\"mae\", \"mse\"]\n",
        "\n",
        "# Create data objects for training using scalar normalization\n",
        "n_inputs = len(input_labels)\n",
        "n_outputs = len(output_labels)\n",
        "x = input_data\n",
        "y = output_data\n",
        "\n",
        "input_scaler = None\n",
        "output_scaler = None\n",
        "input_scaler = OffsetScaler.create_normalizing_scaler(x)\n",
        "output_scaler = OffsetScaler.create_normalizing_scaler(y)\n",
        "x = input_scaler.scale(x)\n",
        "y = output_scaler.scale(y)\n",
        "x = x.to_numpy()\n",
        "y = y.to_numpy()\n",
        "\n",
        "# Create Keras Sequential object and build neural network\n",
        "model = tf.keras.Sequential()\n",
        "model.add(\n",
        "    tf.keras.layers.Dense(\n",
        "        units=n_nodes_per_layer, input_dim=n_inputs, activation=activation\n",
        "    )\n",
        ")\n",
        "for i in range(1, n_hidden_layers):\n",
        "    model.add(tf.keras.layers.Dense(units=n_nodes_per_layer, activation=activation))\n",
        "model.add(tf.keras.layers.Dense(units=n_outputs, activation=keras.activations.linear))\n",
        "\n",
        "# Train surrogate (calls optimizer on neural network and solves for weights)\n",
        "model.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n",
        "mcp_save = tf.keras.callbacks.ModelCheckpoint(\n",
        "    \".mdl_co2.keras\", save_best_only=True, monitor=\"val_loss\", mode=\"min\"\n",
        ")\n",
        "history = model.fit(\n",
        "    x=x, y=y, validation_split=0.2, verbose=2, epochs=250, callbacks=[mcp_save]\n",
        ")\n",
        "\n",
        "# Get the training and validation MSE from the history\n",
        "train_mse = history.history[\"mse\"]\n",
        "val_mse = history.history[\"val_mse\"]\n",
        "\n",
        "# Generate a plot of training MSE vs validation MSE\n",
        "epochs = range(1, len(train_mse) + 1)\n",
        "plt.plot(epochs, train_mse, \"bo-\", label=\"Training MSE\")\n",
        "plt.plot(epochs, val_mse, \"ro-\", label=\"Validation MSE\")\n",
        "plt.title(\"Training MSE vs Validation MSE\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"MSE\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Adding input bounds and variables along with scalers and output variable to kerasSurrogate\n",
        "xmin, xmax = [7, 306], [40, 1000]\n",
        "input_bounds = {input_labels[i]: (xmin[i], xmax[i]) for i in range(len(input_labels))}\n",
        "\n",
        "keras_surrogate = KerasSurrogate(\n",
        "    model,\n",
        "    input_labels=list(input_labels),\n",
        "    output_labels=list(output_labels),\n",
        "    input_bounds=input_bounds,\n",
        "    input_scaler=input_scaler,\n",
        "    output_scaler=output_scaler,\n",
        ")\n",
        "keras_surrogate.save_to_folder(\n",
        "    keras_folder_name=\"sco2_keras_surr\", keras_model_name=\"sco2_keras_model\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.3 Visualizing Surrogates\n",
        "\n",
        "Now that the surrogate models have been trained, the models can be visualized through scatter, parity and residual plots to confirm their validity in the chosen domain. The training data will be visualized first to confirm the surrogates are fit the data, and then the validation data will be visualized to confirm the surrogates accurately predict new output values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "surrogate_scatter2D(keras_surrogate, data_training)\n",
        "surrogate_parity(keras_surrogate, data_training)\n",
        "surrogate_residual(keras_surrogate, data_training)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.4 Model Validation\n",
        "\n",
        "We check the fit on the validation set to see if the surrogate is fitting well. This step can be used to check for overfitting on the training set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# visualize with IDAES surrogate plotting tools\n",
        "surrogate_scatter2D(keras_surrogate, data_validation)\n",
        "surrogate_parity(keras_surrogate, data_validation)\n",
        "surrogate_residual(keras_surrogate, data_validation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, the surrogate is trained and validated, we shall embed it in the property package, which is demonstrated in the [surrogate_embedding_test.ipynb](./surrogate_embedding_test.ipynb) file."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 3
}